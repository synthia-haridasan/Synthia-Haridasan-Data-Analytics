{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDbJWoO1yO8e"
      },
      "source": [
        "# Image Classification with CNN - LeNet5 architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzQxqD6HyO8i"
      },
      "source": [
        "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyVotRvyO8j"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTHLyL1fyO8j",
        "outputId": "d370c5a4-880a-4c54-d59c-0124eeeda1b2",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# TODO: Load the dataset\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# # # If your computer is slow, try to use a subset of data, e.g.\n",
        "# X_train = X_train[:10000]\n",
        "# y_train = y_train[:10000]\n",
        "# X_test = X_test[:2000]\n",
        "# y_test = y_test[:2000]\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ShXIANyO8l"
      },
      "source": [
        "As you already know, this dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BvNG0PbyO8l"
      },
      "source": [
        "You can have a look at some images if needed, even if you already know them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "lnjqgv-GyO8m",
        "outputId": "601a7abc-cfc7-4abd-999f-91455b94a089",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx],cmap=\"gray_r\")\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdYH6XW1yO8n"
      },
      "source": [
        "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fjv8XMPByO8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4749fe5e-c3ba-4618-9f58-206320bbb43e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train,num_classes=10)\n",
        "y_test_cat = to_categorical(y_test,num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/225\n",
        "X_test_norm = X_test/225\n",
        "\n",
        "\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], 28, 28, 1)\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train_norm.shape #Should be (60000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9LKzxR9yO8o"
      },
      "source": [
        "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
        "\n",
        "The architecture is the following:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GKyMFlL6yO8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a22cfa-7cd2-4ffb-c316-7e27084a292d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " C1 (Conv2D)                 (None, 26, 26, 6)         60        \n",
            "                                                                 \n",
            " S2 (MaxPooling2D)           (None, 13, 13, 6)         0         \n",
            "                                                                 \n",
            " C3 (Conv2D)                 (None, 11, 11, 1)         55        \n",
            "                                                                 \n",
            " S4 (MaxPooling2D)           (None, 5, 5, 1)           0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25)                0         \n",
            "                                                                 \n",
            " C5 (Dense)                  (None, 120)               3120      \n",
            "                                                                 \n",
            " F5 (Dense)                  (None, 84)                10164     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,249\n",
            "Trainable params: 14,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
        "\n",
        "\n",
        "def lenet5():\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer C1\n",
        "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "    # Layer S2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
        "    # Layer C3\n",
        "    model.add(Conv2D(filters=1, name='C3',kernel_size=(3,3),activation='relu'))\n",
        "    # Layer S4\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S4'))\n",
        "    # Before going into layer C5, we flatten our units\n",
        "    model.add(Flatten())\n",
        "    # Layer C5\n",
        "    model.add(Dense(120,activation='relu',name=\"C5\"))\n",
        "    # Layer F6\n",
        "    model.add(Dense(84,activation='relu',name=\"F5\"))\n",
        "    # Output layer\n",
        "    model.add(Dense(units=10, activation = 'softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "lenet5().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1qBEauqyO8p"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPL3aKnyyO8p",
        "outputId": "e9a04035-9181-4b4b-b3a1-8267fd8b9419",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 13s 39ms/step - loss: 1.9515 - accuracy: 0.4135 - val_loss: 1.4179 - val_accuracy: 0.5505\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 1.1282 - accuracy: 0.5849 - val_loss: 0.9690 - val_accuracy: 0.6244\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.9007 - accuracy: 0.6572 - val_loss: 0.8618 - val_accuracy: 0.6770\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.8204 - accuracy: 0.6934 - val_loss: 0.8134 - val_accuracy: 0.6991\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.7763 - accuracy: 0.7128 - val_loss: 0.7772 - val_accuracy: 0.7118\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.7402 - accuracy: 0.7276 - val_loss: 0.7514 - val_accuracy: 0.7207\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.7116 - accuracy: 0.7379 - val_loss: 0.7276 - val_accuracy: 0.7329\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.6922 - accuracy: 0.7462 - val_loss: 0.7144 - val_accuracy: 0.7397\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.6758 - accuracy: 0.7507 - val_loss: 0.6912 - val_accuracy: 0.7468\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.6538 - accuracy: 0.7602 - val_loss: 0.6830 - val_accuracy: 0.7502\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.6403 - accuracy: 0.7650 - val_loss: 0.6685 - val_accuracy: 0.7515\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.6250 - accuracy: 0.7692 - val_loss: 0.6480 - val_accuracy: 0.7645\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.6164 - accuracy: 0.7734 - val_loss: 0.6357 - val_accuracy: 0.7681\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.6058 - accuracy: 0.7750 - val_loss: 0.6442 - val_accuracy: 0.7626\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.5976 - accuracy: 0.7782 - val_loss: 0.6174 - val_accuracy: 0.7740\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.5881 - accuracy: 0.7839 - val_loss: 0.6100 - val_accuracy: 0.7773\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.5780 - accuracy: 0.7871 - val_loss: 0.6095 - val_accuracy: 0.7797\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.5716 - accuracy: 0.7904 - val_loss: 0.6074 - val_accuracy: 0.7759\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.5717 - accuracy: 0.7886 - val_loss: 0.5970 - val_accuracy: 0.7782\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.5628 - accuracy: 0.7926 - val_loss: 0.5873 - val_accuracy: 0.7865\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.5562 - accuracy: 0.7951 - val_loss: 0.5879 - val_accuracy: 0.7857\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.5551 - accuracy: 0.7941 - val_loss: 0.5799 - val_accuracy: 0.7880\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.5493 - accuracy: 0.7967 - val_loss: 0.5779 - val_accuracy: 0.7899\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.5506 - accuracy: 0.7954 - val_loss: 0.5934 - val_accuracy: 0.7867\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.5417 - accuracy: 0.7998 - val_loss: 0.5740 - val_accuracy: 0.7869\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.5392 - accuracy: 0.8008 - val_loss: 0.5629 - val_accuracy: 0.7921\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.5356 - accuracy: 0.8015 - val_loss: 0.5695 - val_accuracy: 0.7899\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.5308 - accuracy: 0.8052 - val_loss: 0.5668 - val_accuracy: 0.7926\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.5297 - accuracy: 0.8044 - val_loss: 0.5603 - val_accuracy: 0.7961\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.5225 - accuracy: 0.8072 - val_loss: 0.5588 - val_accuracy: 0.7946\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.5212 - accuracy: 0.8083 - val_loss: 0.5529 - val_accuracy: 0.7995\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.5185 - accuracy: 0.8089 - val_loss: 0.5551 - val_accuracy: 0.7992\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.5160 - accuracy: 0.8095 - val_loss: 0.5459 - val_accuracy: 0.8000\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.5108 - accuracy: 0.8129 - val_loss: 0.5438 - val_accuracy: 0.8040\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.5104 - accuracy: 0.8119 - val_loss: 0.5406 - val_accuracy: 0.8028\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.5102 - accuracy: 0.8111 - val_loss: 0.5410 - val_accuracy: 0.8041\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.5056 - accuracy: 0.8147 - val_loss: 0.5388 - val_accuracy: 0.8045\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.5045 - accuracy: 0.8133 - val_loss: 0.5395 - val_accuracy: 0.8013\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4978 - accuracy: 0.8170 - val_loss: 0.5496 - val_accuracy: 0.7938\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.5038 - accuracy: 0.8131 - val_loss: 0.5370 - val_accuracy: 0.8015\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4925 - accuracy: 0.8185 - val_loss: 0.5355 - val_accuracy: 0.8062\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4900 - accuracy: 0.8200 - val_loss: 0.5291 - val_accuracy: 0.8042\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.4916 - accuracy: 0.8183 - val_loss: 0.5419 - val_accuracy: 0.8008\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.4943 - accuracy: 0.8159 - val_loss: 0.5246 - val_accuracy: 0.8134\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 1s 32ms/step - loss: 0.4872 - accuracy: 0.8206 - val_loss: 0.5263 - val_accuracy: 0.8082\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.4838 - accuracy: 0.8199 - val_loss: 0.5218 - val_accuracy: 0.8117\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 0.4811 - accuracy: 0.8225 - val_loss: 0.5226 - val_accuracy: 0.8070\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.4800 - accuracy: 0.8226 - val_loss: 0.5361 - val_accuracy: 0.8031\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.4858 - accuracy: 0.8190 - val_loss: 0.5140 - val_accuracy: 0.8118\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 0.4763 - accuracy: 0.8245 - val_loss: 0.5169 - val_accuracy: 0.8120\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 1s 32ms/step - loss: 0.4769 - accuracy: 0.8236 - val_loss: 0.5149 - val_accuracy: 0.8122\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.4760 - accuracy: 0.8239 - val_loss: 0.5188 - val_accuracy: 0.8119\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.4742 - accuracy: 0.8238 - val_loss: 0.5087 - val_accuracy: 0.8154\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4685 - accuracy: 0.8272 - val_loss: 0.5100 - val_accuracy: 0.8132\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4658 - accuracy: 0.8281 - val_loss: 0.5073 - val_accuracy: 0.8161\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.4670 - accuracy: 0.8273 - val_loss: 0.5111 - val_accuracy: 0.8114\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.4691 - accuracy: 0.8259 - val_loss: 0.5084 - val_accuracy: 0.8151\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4688 - accuracy: 0.8265 - val_loss: 0.5169 - val_accuracy: 0.8087\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4671 - accuracy: 0.8262 - val_loss: 0.5032 - val_accuracy: 0.8155\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.4691 - accuracy: 0.8250 - val_loss: 0.5065 - val_accuracy: 0.8173\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.4622 - accuracy: 0.8284 - val_loss: 0.4971 - val_accuracy: 0.8211\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.4594 - accuracy: 0.8299 - val_loss: 0.5052 - val_accuracy: 0.8138\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4590 - accuracy: 0.8291 - val_loss: 0.5042 - val_accuracy: 0.8175\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4585 - accuracy: 0.8293 - val_loss: 0.5070 - val_accuracy: 0.8121\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.4585 - accuracy: 0.8298 - val_loss: 0.5091 - val_accuracy: 0.8121\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.4564 - accuracy: 0.8302 - val_loss: 0.5003 - val_accuracy: 0.8157\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.4566 - accuracy: 0.8297 - val_loss: 0.5029 - val_accuracy: 0.8136\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.4534 - accuracy: 0.8312 - val_loss: 0.4962 - val_accuracy: 0.8178\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4561 - accuracy: 0.8298 - val_loss: 0.4917 - val_accuracy: 0.8185\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4494 - accuracy: 0.8328 - val_loss: 0.4923 - val_accuracy: 0.8223\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4507 - accuracy: 0.8329 - val_loss: 0.5013 - val_accuracy: 0.8174\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 0.4500 - accuracy: 0.8314 - val_loss: 0.4925 - val_accuracy: 0.8192\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.4492 - accuracy: 0.8335 - val_loss: 0.4917 - val_accuracy: 0.8204\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.4494 - accuracy: 0.8318 - val_loss: 0.4891 - val_accuracy: 0.8229\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.4490 - accuracy: 0.8327 - val_loss: 0.4893 - val_accuracy: 0.8205\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.4445 - accuracy: 0.8347 - val_loss: 0.4875 - val_accuracy: 0.8236\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4449 - accuracy: 0.8340 - val_loss: 0.4905 - val_accuracy: 0.8206\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4436 - accuracy: 0.8347 - val_loss: 0.4967 - val_accuracy: 0.8169\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4421 - accuracy: 0.8354 - val_loss: 0.4869 - val_accuracy: 0.8220\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 0.4447 - accuracy: 0.8338 - val_loss: 0.4919 - val_accuracy: 0.8202\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 1s 32ms/step - loss: 0.4445 - accuracy: 0.8337 - val_loss: 0.4887 - val_accuracy: 0.8192\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.4402 - accuracy: 0.8368 - val_loss: 0.4913 - val_accuracy: 0.8187\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.4415 - accuracy: 0.8348 - val_loss: 0.4839 - val_accuracy: 0.8228\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4405 - accuracy: 0.8357 - val_loss: 0.4888 - val_accuracy: 0.8226\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4345 - accuracy: 0.8385 - val_loss: 0.4873 - val_accuracy: 0.8218\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4372 - accuracy: 0.8362 - val_loss: 0.4857 - val_accuracy: 0.8216\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4335 - accuracy: 0.8389 - val_loss: 0.4805 - val_accuracy: 0.8232\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4335 - accuracy: 0.8382 - val_loss: 0.4789 - val_accuracy: 0.8270\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4342 - accuracy: 0.8386 - val_loss: 0.4841 - val_accuracy: 0.8218\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4344 - accuracy: 0.8379 - val_loss: 0.4767 - val_accuracy: 0.8265\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4302 - accuracy: 0.8404 - val_loss: 0.4757 - val_accuracy: 0.8283\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4309 - accuracy: 0.8403 - val_loss: 0.4758 - val_accuracy: 0.8267\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4308 - accuracy: 0.8394 - val_loss: 0.4787 - val_accuracy: 0.8230\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4283 - accuracy: 0.8403 - val_loss: 0.4767 - val_accuracy: 0.8249\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4279 - accuracy: 0.8411 - val_loss: 0.4756 - val_accuracy: 0.8268\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.4277 - accuracy: 0.8398 - val_loss: 0.4750 - val_accuracy: 0.8282\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4286 - accuracy: 0.8404 - val_loss: 0.4822 - val_accuracy: 0.8234\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4317 - accuracy: 0.8396 - val_loss: 0.4824 - val_accuracy: 0.8256\n",
            "Epoch 99/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.4256 - accuracy: 0.8418 - val_loss: 0.4753 - val_accuracy: 0.8256\n",
            "Epoch 100/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.4222 - accuracy: 0.8425 - val_loss: 0.4722 - val_accuracy: 0.8291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd199f7e950>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# TODO: Compile and fit your model\n",
        "import os\n",
        "\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "model = lenet5()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define now our callbacks\n",
        "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "\n",
        "# Finally fit the model\n",
        "model.fit(x=X_train_norm, y=y_train_cat, validation_data=(X_test_norm, y_test_cat), epochs=100, batch_size=2048, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf-SqjjOyO8q"
      },
      "source": [
        "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2FTj7TSyO8q"
      },
      "source": [
        "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPjJoMQZyO8q",
        "outputId": "d6addcc1-ffd8-4dc7-a737-637af8598873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on train with CNN: 0.8457833333333333\n",
            "accuracy on test with CNN: 0.8291\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size = 1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vulsgHiyO8q"
      },
      "source": [
        "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
        "\n",
        "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter: \n",
        "* `horizontal_flip=True`\n",
        "\n",
        "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
        "\n",
        "Begin by creating an object `ImageDataGenerator` with this parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-19T11:58:37.442182Z",
          "start_time": "2020-08-19T11:58:37.438397Z"
        },
        "id": "pas-fMSIyO8q"
      },
      "outputs": [],
      "source": [
        "# TODO: Instantiate an ImageDataGenerator object\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7nCnu9syO8r"
      },
      "source": [
        "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt6wXa3IyO8r",
        "outputId": "de294918-396e-4a4b-8b9e-8d110430b189",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 4s 70ms/step - loss: 0.6989 - accuracy: 0.7761 - val_loss: 0.5174 - val_accuracy: 0.8119\n",
            "Epoch 2/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.4993 - accuracy: 0.8143 - val_loss: 0.5025 - val_accuracy: 0.8187\n",
            "Epoch 3/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.4796 - accuracy: 0.8219 - val_loss: 0.5007 - val_accuracy: 0.8174\n",
            "Epoch 4/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.4769 - accuracy: 0.8219 - val_loss: 0.4905 - val_accuracy: 0.8192\n",
            "Epoch 5/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.4683 - accuracy: 0.8247 - val_loss: 0.4965 - val_accuracy: 0.8186\n",
            "Epoch 6/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.4648 - accuracy: 0.8268 - val_loss: 0.4889 - val_accuracy: 0.8217\n",
            "Epoch 7/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.4635 - accuracy: 0.8267 - val_loss: 0.4894 - val_accuracy: 0.8213\n",
            "Epoch 8/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.4582 - accuracy: 0.8274 - val_loss: 0.4867 - val_accuracy: 0.8224\n",
            "Epoch 9/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.4579 - accuracy: 0.8281 - val_loss: 0.4940 - val_accuracy: 0.8176\n",
            "Epoch 10/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.4535 - accuracy: 0.8293 - val_loss: 0.4959 - val_accuracy: 0.8124\n",
            "Epoch 11/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.4555 - accuracy: 0.8294 - val_loss: 0.4879 - val_accuracy: 0.8189\n",
            "Epoch 12/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.4485 - accuracy: 0.8313 - val_loss: 0.4922 - val_accuracy: 0.8190\n",
            "Epoch 13/100\n",
            "58/58 [==============================] - 3s 50ms/step - loss: 0.4459 - accuracy: 0.8320 - val_loss: 0.4849 - val_accuracy: 0.8212\n",
            "Epoch 14/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.4444 - accuracy: 0.8323 - val_loss: 0.4809 - val_accuracy: 0.8241\n",
            "Epoch 15/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.4453 - accuracy: 0.8319 - val_loss: 0.4990 - val_accuracy: 0.8134\n",
            "Epoch 16/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.4469 - accuracy: 0.8326 - val_loss: 0.4871 - val_accuracy: 0.8204\n",
            "Epoch 17/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.4446 - accuracy: 0.8312 - val_loss: 0.4817 - val_accuracy: 0.8191\n",
            "Epoch 18/100\n",
            "58/58 [==============================] - 3s 55ms/step - loss: 0.4395 - accuracy: 0.8347 - val_loss: 0.4772 - val_accuracy: 0.8237\n",
            "Epoch 19/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.4372 - accuracy: 0.8352 - val_loss: 0.4806 - val_accuracy: 0.8214\n",
            "Epoch 20/100\n",
            "58/58 [==============================] - 3s 56ms/step - loss: 0.4390 - accuracy: 0.8340 - val_loss: 0.4864 - val_accuracy: 0.8201\n",
            "Epoch 21/100\n",
            "58/58 [==============================] - 3s 55ms/step - loss: 0.4368 - accuracy: 0.8360 - val_loss: 0.4813 - val_accuracy: 0.8226\n",
            "Epoch 22/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.4365 - accuracy: 0.8363 - val_loss: 0.4751 - val_accuracy: 0.8253\n",
            "Epoch 23/100\n",
            "58/58 [==============================] - 4s 69ms/step - loss: 0.4323 - accuracy: 0.8371 - val_loss: 0.4728 - val_accuracy: 0.8252\n",
            "Epoch 24/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.4314 - accuracy: 0.8363 - val_loss: 0.4717 - val_accuracy: 0.8276\n",
            "Epoch 25/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.4317 - accuracy: 0.8370 - val_loss: 0.4812 - val_accuracy: 0.8232\n",
            "Epoch 26/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.4333 - accuracy: 0.8363 - val_loss: 0.4751 - val_accuracy: 0.8227\n",
            "Epoch 27/100\n",
            "58/58 [==============================] - 4s 64ms/step - loss: 0.4317 - accuracy: 0.8378 - val_loss: 0.4738 - val_accuracy: 0.8267\n",
            "Epoch 28/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.4258 - accuracy: 0.8402 - val_loss: 0.4742 - val_accuracy: 0.8272\n",
            "Epoch 29/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.4289 - accuracy: 0.8380 - val_loss: 0.4723 - val_accuracy: 0.8246\n",
            "Epoch 30/100\n",
            "58/58 [==============================] - 4s 76ms/step - loss: 0.4256 - accuracy: 0.8385 - val_loss: 0.4714 - val_accuracy: 0.8273\n",
            "Epoch 31/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.4276 - accuracy: 0.8391 - val_loss: 0.4694 - val_accuracy: 0.8274\n",
            "Epoch 32/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.4247 - accuracy: 0.8401 - val_loss: 0.4756 - val_accuracy: 0.8260\n",
            "Epoch 33/100\n",
            "58/58 [==============================] - 3s 51ms/step - loss: 0.4261 - accuracy: 0.8389 - val_loss: 0.4837 - val_accuracy: 0.8206\n",
            "Epoch 34/100\n",
            "58/58 [==============================] - 3s 51ms/step - loss: 0.4272 - accuracy: 0.8396 - val_loss: 0.4749 - val_accuracy: 0.8249\n",
            "Epoch 35/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.4232 - accuracy: 0.8400 - val_loss: 0.4689 - val_accuracy: 0.8254\n",
            "Epoch 36/100\n",
            "58/58 [==============================] - 3s 44ms/step - loss: 0.4273 - accuracy: 0.8394 - val_loss: 0.4856 - val_accuracy: 0.8210\n",
            "Epoch 37/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.4210 - accuracy: 0.8426 - val_loss: 0.4729 - val_accuracy: 0.8260\n",
            "Epoch 38/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.4236 - accuracy: 0.8400 - val_loss: 0.4611 - val_accuracy: 0.8285\n",
            "Epoch 39/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.4177 - accuracy: 0.8424 - val_loss: 0.4631 - val_accuracy: 0.8283\n",
            "Epoch 40/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.4199 - accuracy: 0.8428 - val_loss: 0.4640 - val_accuracy: 0.8303\n",
            "Epoch 41/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.4211 - accuracy: 0.8422 - val_loss: 0.4668 - val_accuracy: 0.8313\n",
            "Epoch 42/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.4147 - accuracy: 0.8438 - val_loss: 0.4604 - val_accuracy: 0.8325\n",
            "Epoch 43/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.4135 - accuracy: 0.8441 - val_loss: 0.4636 - val_accuracy: 0.8268\n",
            "Epoch 44/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.4123 - accuracy: 0.8455 - val_loss: 0.4699 - val_accuracy: 0.8309\n",
            "Epoch 45/100\n",
            "58/58 [==============================] - 4s 63ms/step - loss: 0.4131 - accuracy: 0.8434 - val_loss: 0.4592 - val_accuracy: 0.8289\n",
            "Epoch 46/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.4121 - accuracy: 0.8454 - val_loss: 0.4659 - val_accuracy: 0.8272\n",
            "Epoch 47/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.4133 - accuracy: 0.8439 - val_loss: 0.4709 - val_accuracy: 0.8274\n",
            "Epoch 48/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.4140 - accuracy: 0.8445 - val_loss: 0.4681 - val_accuracy: 0.8276\n",
            "Epoch 49/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.4096 - accuracy: 0.8453 - val_loss: 0.4613 - val_accuracy: 0.8297\n",
            "Epoch 50/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.4078 - accuracy: 0.8462 - val_loss: 0.4594 - val_accuracy: 0.8320\n",
            "Epoch 51/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.4086 - accuracy: 0.8449 - val_loss: 0.4532 - val_accuracy: 0.8321\n",
            "Epoch 52/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.4076 - accuracy: 0.8468 - val_loss: 0.4553 - val_accuracy: 0.8351\n",
            "Epoch 53/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.4069 - accuracy: 0.8470 - val_loss: 0.4664 - val_accuracy: 0.8278\n",
            "Epoch 54/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.4098 - accuracy: 0.8447 - val_loss: 0.4677 - val_accuracy: 0.8253\n",
            "Epoch 55/100\n",
            "58/58 [==============================] - 4s 62ms/step - loss: 0.4073 - accuracy: 0.8457 - val_loss: 0.4579 - val_accuracy: 0.8292\n",
            "Epoch 56/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.4078 - accuracy: 0.8452 - val_loss: 0.4586 - val_accuracy: 0.8328\n",
            "Epoch 57/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.4059 - accuracy: 0.8454 - val_loss: 0.4506 - val_accuracy: 0.8356\n",
            "Epoch 58/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.4050 - accuracy: 0.8472 - val_loss: 0.4571 - val_accuracy: 0.8337\n",
            "Epoch 59/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.4032 - accuracy: 0.8478 - val_loss: 0.4611 - val_accuracy: 0.8317\n",
            "Epoch 60/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.4041 - accuracy: 0.8479 - val_loss: 0.4483 - val_accuracy: 0.8336\n",
            "Epoch 61/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.4030 - accuracy: 0.8468 - val_loss: 0.4541 - val_accuracy: 0.8332\n",
            "Epoch 62/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.3996 - accuracy: 0.8488 - val_loss: 0.4475 - val_accuracy: 0.8359\n",
            "Epoch 63/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.3993 - accuracy: 0.8497 - val_loss: 0.4479 - val_accuracy: 0.8363\n",
            "Epoch 64/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.4034 - accuracy: 0.8469 - val_loss: 0.4531 - val_accuracy: 0.8344\n",
            "Epoch 65/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.3981 - accuracy: 0.8485 - val_loss: 0.4534 - val_accuracy: 0.8319\n",
            "Epoch 66/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.4047 - accuracy: 0.8468 - val_loss: 0.4556 - val_accuracy: 0.8336\n",
            "Epoch 67/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.4001 - accuracy: 0.8496 - val_loss: 0.4644 - val_accuracy: 0.8279\n",
            "Epoch 68/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.3990 - accuracy: 0.8477 - val_loss: 0.4553 - val_accuracy: 0.8330\n",
            "Epoch 69/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.3966 - accuracy: 0.8500 - val_loss: 0.4469 - val_accuracy: 0.8356\n",
            "Epoch 70/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.3977 - accuracy: 0.8499 - val_loss: 0.4563 - val_accuracy: 0.8333\n",
            "Epoch 71/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.3958 - accuracy: 0.8514 - val_loss: 0.4508 - val_accuracy: 0.8322\n",
            "Epoch 72/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.4000 - accuracy: 0.8487 - val_loss: 0.4449 - val_accuracy: 0.8379\n",
            "Epoch 73/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.3933 - accuracy: 0.8508 - val_loss: 0.4461 - val_accuracy: 0.8376\n",
            "Epoch 74/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.3938 - accuracy: 0.8502 - val_loss: 0.4519 - val_accuracy: 0.8318\n",
            "Epoch 75/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.3963 - accuracy: 0.8494 - val_loss: 0.4552 - val_accuracy: 0.8314\n",
            "Epoch 76/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.3965 - accuracy: 0.8488 - val_loss: 0.4492 - val_accuracy: 0.8344\n",
            "Epoch 77/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.3924 - accuracy: 0.8521 - val_loss: 0.4478 - val_accuracy: 0.8358\n",
            "Epoch 78/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.3927 - accuracy: 0.8511 - val_loss: 0.4450 - val_accuracy: 0.8373\n",
            "Epoch 79/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.3914 - accuracy: 0.8522 - val_loss: 0.4480 - val_accuracy: 0.8373\n",
            "Epoch 80/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.3904 - accuracy: 0.8523 - val_loss: 0.4393 - val_accuracy: 0.8384\n",
            "Epoch 81/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.3926 - accuracy: 0.8513 - val_loss: 0.4425 - val_accuracy: 0.8379\n",
            "Epoch 82/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.3903 - accuracy: 0.8524 - val_loss: 0.4433 - val_accuracy: 0.8383\n",
            "Epoch 83/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.3905 - accuracy: 0.8511 - val_loss: 0.4403 - val_accuracy: 0.8397\n",
            "Epoch 84/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.3901 - accuracy: 0.8522 - val_loss: 0.4405 - val_accuracy: 0.8375\n",
            "Epoch 85/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.3880 - accuracy: 0.8542 - val_loss: 0.4445 - val_accuracy: 0.8341\n",
            "Epoch 86/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.3914 - accuracy: 0.8511 - val_loss: 0.4468 - val_accuracy: 0.8354\n",
            "Epoch 87/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.3915 - accuracy: 0.8528 - val_loss: 0.4458 - val_accuracy: 0.8381\n",
            "Epoch 88/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.3878 - accuracy: 0.8542 - val_loss: 0.4441 - val_accuracy: 0.8396\n",
            "Epoch 89/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.3871 - accuracy: 0.8540 - val_loss: 0.4452 - val_accuracy: 0.8361\n",
            "Epoch 90/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.3870 - accuracy: 0.8530 - val_loss: 0.4451 - val_accuracy: 0.8385\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd2100e5f50>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# TODO: train your model\n",
        "batch_size = 1024\n",
        "model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
        "                    validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
        "                    steps_per_epoch=len(X_train_norm) / batch_size, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuzFke8pyO8r"
      },
      "source": [
        "Recompute the accuracy of your model, does it improve your performances with data augmentation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsTm86tuyO8r",
        "outputId": "e605232d-0e6a-4bbd-d892-c02e0cff4356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on train with NN: 0.8537666666666667\n",
            "accuracy on test with NN: 0.8385\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size=1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOzkdGf7yO8s"
      },
      "source": [
        "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LeNet5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}