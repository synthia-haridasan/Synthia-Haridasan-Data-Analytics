{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04-Spam-Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to make our first real Machine Learning application of NLP: a spam classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A spam classifier is a Machine Learning model that classifier texts (email or SMS) into two categories: Spam (1) or legitimate (0).\n",
    "\n",
    "To do that, we will reuse our knowledge: we will apply preprocessing and BOW (Bag Of Words) on a dataset of texts.\n",
    "Then we will use a classifier to predict to which class belong a new email/SMS, based on the BOW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first: import the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NLTK and all the needed libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load now the dataset in *spam.csv* using pandas. Use the 'latin-1' encoding as loading option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                            Message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Load the dataset \n",
    "df = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, I suggest you to explore a bit this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Class    5572 non-null   object\n",
      " 1   Message  5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# TODO: explore the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as you see we have a column containing the labels, and a column containing the text to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by doing the usual preprocessing: tokenization, punctuation removal and lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\synth\\AppData\\Local\\Temp/ipykernel_30288/3669219589.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Message'] = df['Message'].str.replace('[^a-zA-Z0-9 ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [Go, until, jurong, point, crazy, Available, o...\n",
      "1                          [Ok, lar, Joking, wif, u, oni]\n",
      "2       [Free, entry, in, 2, a, wkly, comp, to, win, F...\n",
      "3       [U, dun, say, so, early, hor, U, c, already, t...\n",
      "4       [Nah, I, dont, think, he, go, to, usf, he, lif...\n",
      "                              ...                        \n",
      "5567    [This, is, the, 2nd, time, we, have, tried, 2,...\n",
      "5568            [Will, b, going, to, esplanade, fr, home]\n",
      "5569    [Pity, wa, in, mood, for, that, Soany, other, ...\n",
      "5570    [The, guy, did, some, bitching, but, I, acted,...\n",
      "5571                      [Rofl, Its, true, to, it, name]\n",
      "Name: tokens, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# TODO: Perform preprocessing over all the text\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "\treturn [lemmatizer.lemmatize(w) for w in text]\n",
    "df['Message'] = df['Message'].str.replace('[^a-zA-Z0-9 ]', '')\n",
    "df['tokens'] = df['Message'].apply(word_tokenize)\n",
    "df['tokens'] = df['tokens'].apply(lemmatize_text)\n",
    "print(df[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok now we have our preprocessed data. Next step is to do a BOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute the BOW\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "BOW = vectorizer.fit_transform(df['Message']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make a new dataframe as usual to have a visual idea of the words used and their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089my</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>020603</th>\n",
       "      <th>0207</th>\n",
       "      <th>02070836089</th>\n",
       "      <th>...</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zed</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   008704050406  0089my  0121  01223585236  01223585334  0125698789  02  \\\n",
       "0             0       0     0            0            0           0   0   \n",
       "1             0       0     0            0            0           0   0   \n",
       "2             0       0     0            0            0           0   0   \n",
       "3             0       0     0            0            0           0   0   \n",
       "4             0       0     0            0            0           0   0   \n",
       "\n",
       "   020603  0207  02070836089  ...  zebra  zed  zeros  zhong  zindgi  zoe  \\\n",
       "0       0     0            0  ...      0    0      0      0       0    0   \n",
       "1       0     0            0  ...      0    0      0      0       0    0   \n",
       "2       0     0            0  ...      0    0      0      0       0    0   \n",
       "3       0     0            0  ...      0    0      0      0       0    0   \n",
       "4       0     0            0  ...      0    0      0      0       0    0   \n",
       "\n",
       "   zogtorius  zoom  zouk  zyada  \n",
       "0          0     0     0      0  \n",
       "1          0     0     0      0  \n",
       "2          0     0     0      0  \n",
       "3          0     0     0      0  \n",
       "4          0     0     0      0  \n",
       "\n",
       "[5 rows x 9271 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Make a new dataframe with the BOW\n",
    "bow_df = pd.DataFrame(data=BOW, columns=vectorizer.get_feature_names())\n",
    "bow_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what is the most used word in the spam category and the non spam category.\n",
    "\n",
    "There are two steps: first add the class to the BOW dataframe. Second, filter on a class, sum all the values and print the most frequent one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most frequent spam word: free\n",
      "most frequent non spam word: im\n"
     ]
    }
   ],
   "source": [
    "# TODO: print the most used word in the spam and non spam category\n",
    "tmp= bow_df\n",
    "tmp[\"Class\"]=df[\"Class\"]\n",
    "most_freq_spam= tmp[tmp[\"Class\"]=='spam'].drop(columns=\"Class\").sum().idxmax()\n",
    "most_freq_nonspam= tmp[tmp[\"Class\"]=='ham'].drop(columns=\"Class\").sum().idxmax()\n",
    "print(\"most frequent spam word:\" ,most_freq_spam)\n",
    "print(\"most frequent non spam word:\" ,most_freq_nonspam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should find that the most frequent spam word is 'free', not so surprising, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make a classifier based on our BOW. We will use a simple logistic regression here for the example.\n",
    "\n",
    "You're an expert, you know what to do, right? Split the data, train your model, predict and see the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9748878923766816"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Perform a classification to predict whether a message is a spam or not\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df[\"Class\"])\n",
    "print(le.transform(df[\"Class\"]))\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(bow_df.drop(columns=\"Class\"), le.transform(df[\"Class\"]), test_size=0.2, random_state=42)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(x_train,y_train)\n",
    "test_pred= classifier.predict(x_test)\n",
    "accuracy_score(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What precision do you get? Check by hand on some samples where it did predict well to check what could go wrong...\n",
    "\n",
    "Try to use other models and try to improve your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "matrix=confusion_matrix(y_test,test_pred)\n",
    "sns.heatmap(matrix, annot=True, fmt='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the above matrix, we can see that there are no true negatives and most of the data are either true positive or true negative. This implies the accuracy of this algorithm is high."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
